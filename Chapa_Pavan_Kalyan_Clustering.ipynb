# Import necessary libraries
import pandas as pd  # For data manipulation and analysis
from sklearn.preprocessing import StandardScaler  # For feature scaling
from sklearn.cluster import KMeans  # For K-Means clustering
from sklearn.metrics import davies_bouldin_score  # For evaluating clustering performance
import matplotlib.pyplot as plt  # For plotting
import seaborn as sns  # For enhanced data visualization

# Load the data from CSV files
customers = pd.read_csv('Customers.csv')  # Load customer data
transactions = pd.read_csv('Transactions.csv')  # Load transaction data

# Data Preprocessing
# Merge transactions with customers to get a complete transaction history
merged_data = transactions.merge(customers, on='CustomerID', how='left')  # Merge on CustomerID

# Feature Engineering
# Create a feature for total transaction value per customer
customer_transaction_value = merged_data.groupby('CustomerID')['TotalValue'].sum().reset_index()
customer_transaction_value.columns = ['CustomerID', 'TotalTransactionValue']  # Rename columns for clarity

# Create a feature for the number of transactions per customer
customer_transaction_count = merged_data.groupby('CustomerID')['TransactionID'].count().reset_index()
customer_transaction_count.columns = ['CustomerID', 'TransactionCount']  # Rename columns for clarity

# Merge the calculated features back into the customer data
customer_features = customers.merge(customer_transaction_value, on='CustomerID', how='left')
customer_features = customer_features.merge(customer_transaction_count, on='CustomerID', how='left')

# Fill any NaN values with 0 (for customers with no transactions)
customer_features.fillna(0, inplace=True)

# Select relevant features for clustering
features = customer_features[['TotalTransactionValue', 'TransactionCount']]  # Select features for clustering

# Standardize the features to have a mean of 0 and a standard deviation of 1
scaler = StandardScaler()  # Initialize the scaler
scaled_features = scaler.fit_transform(features)  # Fit and transform the features

# Clustering
# Choose the number of clusters (between 2 and 10)
n_clusters = 5  # Set the number of clusters for K-Means
kmeans = KMeans(n_clusters=n_clusters, random_state=42)  # Initialize K-Means with the specified number of clusters
customer_features['Cluster'] = kmeans.fit_predict(scaled_features)  # Fit the model and predict cluster labels

# Evaluation: Calculate the Davies-Bouldin Index
db_index = davies_bouldin_score(scaled_features, customer_features['Cluster'])  # Calculate DB Index
print(f'Davies-Bouldin Index for {n_clusters} clusters: {db_index}')  # Print the DB Index

# Visualization
# Set the style for seaborn
sns.set(style="whitegrid")  # Set the style for the plots

# Create a scatter plot of the clusters
plt.figure(figsize=(10, 6))  # Set the figure size
sns.scatterplot(x='TotalTransactionValue', y='TransactionCount', hue='Cluster', data=customer_features, palette='viridis', s=100)
plt.title(f'Customer Segmentation using K-Means Clustering (n_clusters={n_clusters})')  # Set the title
plt.xlabel('Total Transaction Value')  # Set the x-axis label
plt.ylabel('Transaction Count')  # Set the y-axis label
plt.legend(title='Cluster')  # Add a legend
plt.show()  # Display the plot

# Optional: Visualize cluster centers
centers = scaler.inverse_transform(kmeans.cluster_centers_)  # Inverse transform the cluster centers to original scale
plt.figure(figsize=(8, 5))  # Set the figure size
plt.scatter(features['TotalTransactionValue'], features['TransactionCount'], c=customer_features['Cluster'], cmap='viridis', s=100)  # Scatter plot of customers
plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=200, label='Centroids')  # Plot the centroids
plt.title('Customer Segmentation with Cluster Centers')  # Set the title
plt.xlabel('Total Transaction Value')  # Set the x-axis label
plt.ylabel('Transaction Count')  # Set the y-axis label
plt.legend()  # Add a legend
plt.show()  # Display the plot